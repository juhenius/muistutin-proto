<project>
This is a NextJS 15 / React 19 / Typescript / Tailwind CSS application with Jest and Cypress test frameworks.
</project>

<tools>
# Internal Tools: Core capabilities available directly.
run_terminal_cmd
codebase_search
read_file
list_dir
grep_search
edit_file
file_search
delete_file
reapply
fetch_rules
web_search
mcp_puppeteer_puppeteer_navigate
mcp_puppeteer_puppeteer_screenshot
mcp_puppeteer_puppeteer_click
mcp_puppeteer_puppeteer_fill
mcp_puppeteer_puppeteer_select
mcp_puppeteer_puppeteer_hover
mcp_puppeteer_puppeteer_evaluate
mcp_supabase_query
</tools>

<command_line_tools>
# Project-Specific Tools: Execute these using `run_terminal_cmd`.
{
  "tools": {
    "translations": {
      "description": "Tools for managing translations and localization",
      "tool": "run_terminal_cmd",
      "command": "npm run",
      "options": {
        "check-translations": "Compare English, Finnish and Swedish translation files for completeness and missing keys",
        "import-translations:local": "Import translations for local development environment",
        "import-translations:prod": "Import translations for production environment",
        "split-locales": "Split monolithic locale files into separate namespace-based files for each locale (en, fi, sv)"
      }
    },
    "seed": {
      "description": "Tools for seeding development and production data",
      "tool": "run_terminal_cmd",
      "command": "npm run",
      "options": {
        "seed:users": "Seed users data for development environment",
        "seed:users:local": "Seed users data for local development",
        "seed:users:prod": "Seed users data for production environment",
        "seed:blog:local": "Seed blog data for local development",
        "seed:blog:prod": "Seed blog data for production environment"
      }
    },
    "supabase": {
      "description": "Manages Supabase database migrations, schema updates, and content seeding",
      "tool": "run_terminal_cmd",
      "command": "supabase",
      "options": {
        "migration": {
          "new": "Create a new migration file"
        },
        "db": {
          "push": "Push database migration changes",
          "reset": "Reset the database"
        },
      },
    },
    "image-optimizer": {
      "description": "Optimizes images with background removal, resizing, and format conversion using Sharp and Replicate's remove-bg model",
      "tool": "run_terminal_cmd",
      "command": "npm run optimize-image",
      "options": {
        "input": "Path to input image",
        "output": "Path to output image",
        "remove-bg": "(Optional) Remove image background using AI",
        "resize": "(Optional) Resize image (format: WIDTHxHEIGHT, e.g. 800x600)",
        "format": "(Optional) Convert to format (png, jpeg, or webp)",
        "quality": "(Optional) Set output quality (1-100, default: 80)"
      },
      "requires": [
        "REPLICATE_API_TOKEN in .env",
        "sharp package (npm install sharp)"
      ],
      "example": "npm run optimize-image -- input.png output.webp --resize 512x512 --format webp --quality 90"
    },
    "html-to-md": {
      "description": "Scrapes a webpage and converts its HTML content to Markdown format using Turndown service",
      "tool": "run_terminal_cmd",
      "command": "npm run html-to-md",
      "options": {
        "url": "URL of the webpage to scrape",
        "output": "(Optional) Output file path for the markdown (default: output.md)",
        "selector": "(Optional) CSS selector to target specific content"
      },
      "requires": [
        "Node.js >= 14",
        "turndown package",
        "axios package"
      ],
      "example": "npm run html-to-md -- --url https://example.com --output docs/scraped.md --selector main"
    },
    "gemini": {
      "description": "Interacts with Google's Gemini API for text generation, chat, multimodal tasks, document analysis, and grounded search",
      "tool": "run_terminal_cmd",
      "command": "npm run gemini",
      "options": {
        "prompt": "Text prompt or question for the model",
        "model": "(Optional) Model to use: 'gemini-2.0-flash' (default), 'gemini-2.5-pro-exp-03-25'",
        "temperature": "(Optional) Sampling temperature between 0.0 and 1.0 (default: 0.7)",
        "max-tokens": "(Optional) Maximum tokens to generate (default: 2048)",
        "image": "(Optional) Path to image file for vision tasks",
        "file": "(Optional) Path to local file (PDF, DOCX, TXT, etc.) for document analysis",
        "url": "(Optional) URL to a document to analyze (PDF, DOCX, TXT, etc.)",
        "mime-type": "(Optional) MIME type of the file (e.g., application/pdf, default: auto-detected)",
        "chat-history": "(Optional) Path to JSON file containing chat history",
        "stream": "(Optional) Stream the response (default: false)",
        "safety-settings": "(Optional) JSON string of safety threshold configurations",
        "schema": "(Optional) JSON schema for structured output",
        "json": "(Optional) Return structured JSON data. Available types: recipes, tasks, products, custom",
        "ground": "(Optional) Enable Google Search grounding for up-to-date information (default: false)",
        "show-search-data": "(Optional) Show the search entries used for grounding (default: false)"
      },
      "requires": [
        "GOOGLE_AI_STUDIO_KEY in .env",
        "@google/genai package",
        "node-fetch package"
      ],
      "example": "npm run gemini -- --prompt "What is the capital of France?" --model gemini-2.0-flash-001 --temperature 0.7",
      "advanced_examples": [
        "# Process a PDF document from a URL",
        "npm run gemini -- --prompt "Summarize this document in 5 key points" --url "https://discovery.ucl.ac.uk/id/eprint/10089234/1/343019_3_art_0_py4t4l_convrt.pdf"",
        "",
        "# Process a local PDF file",
        "npm run gemini -- --prompt "What is this document about?" --file test/data/sample.pdf",
        "",
        "# Process a text file with specific MIME type",
        "npm run gemini -- --prompt "Expand on this information" --file test/data/sample.txt --mime-type text/plain",
        "",
        "# Get grounded search results with real-time information",
        "npm run gemini -- --prompt "When is the next total solar eclipse in North America?" --ground --show-search-data",
        "",
        "# Generate structured JSON data with predefined schema (recipes)",
        "npm run gemini -- --prompt "List 3 popular cookie recipes" --json recipes",
        "",
        "# Generate structured JSON data with predefined schema (tasks)",
        "npm run gemini -- --prompt "Create a task list for planning a vacation" --json tasks",
        "",
        "# Generate structured JSON data with predefined schema (products)",
        "npm run gemini -- --prompt "List 3 smartphone models" --json products",
        "",
        "# Use a custom JSON schema for structured output",
        "npm run gemini -- --prompt "List 3 programming languages and their use cases" --json custom --schema '{"type":"array","items":{"type":"object","properties":{"language":{"type":"string"},"year":{"type":"integer"},"useCases":{"type":"array","items":{"type":"string"}}},"required":["language","useCases"]}}'"
      ]
    },
    "gemini-image": {
      "description": "Generates and edits images using Google Gemini and Imagen models",
      "tool": "run_terminal_cmd",
      "command": "node tools/gemini-image-tool.js",
      "subcommands": {
        "generate": {
          "description": "Generate an image using Gemini 2.0 or Imagen 3.0",
          "options": {
            "prompt": "Required: Text prompt for image generation",
            "model": "(Optional) Model to use: 'gemini-2.0' (default) or 'imagen-3.0'",
            "output": "(Optional) Output file path (default: gemini-generated-image.png)",
            "folder": "(Optional) Output folder path (default: public/images)",
            "num-outputs": "(Optional) Number of images (Imagen 3 only, default: 1, max: 4)",
            "negative-prompt": "(Optional) Negative prompt (Imagen 3 only)",
            "aspect-ratio": "(Optional) Aspect ratio (Imagen 3 only, default: 1:1, options: 1:1, 16:9, 9:16, 4:3, 3:4)"
          },
          "example": "node tools/gemini-image-tool.js generate -p "A futuristic car" -m imagen-3.0 -n 2 --aspect-ratio 16:9 -o car.png"
        },
        "edit": {
          "description": "Edit an existing image using Gemini 2.0",
          "options": {
            "input-image": "Required: Path to the input image",
            "edit-prompt": "Required: Text prompt describing the edit",
            "output": "(Optional) Output file path (default: gemini-edited-image.png)",
            "folder": "(Optional) Output folder path (default: public/images)"
          },
          "example": "node tools/gemini-image-tool.js edit -i input.png -p "Add sunglasses to the person" -o edited.png"
        }
      },
      "requires": [
        "GOOGLE_AI_STUDIO_KEY or GEMINI_API_KEY in .env.local",
        "@google/genai package",
        "commander package",
        "axios package",
        "dotenv package"
      ]
    },
    "download-file": {
      "description": "Downloads files from URLs with progress tracking, automatic file type detection, and customizable output paths",
      "tool": "run_terminal_cmd",
      "command": "npm run download-file",
      "options": {
        "url": "URL of the file to download",
        "output": "(Optional) Complete output path including filename",
        "folder": "(Optional) Output folder path (default: downloads)",
        "filename": "(Optional) Output filename (if not provided, derived from URL or content)"
      },
      "requires": [
        "axios package",
        "cli-progress package",
        "mime-types package"
      ],
      "example": "npm run download-file -- --url https://example.com/image.jpg --folder public/images --filename downloaded-image.jpg"
    },
    "generate-video": {
      "description": "Generates videos using various Replicate API models. Can optionally first generate an image using OpenAI (GPT-image-1) based on an image prompt, then use that image for video generation.",
      "tool": "run_terminal_cmd",
      "command": "npm run generate-video",
      "options": {
        "prompt": "Text description of the desired video (used by Replicate).",
        "model": "(Optional) Replicate model to use: kling-1.6 (default), kling-2.0, minimax, hunyuan, mochi, or ltx.",
        "duration": "(Optional) Duration of the video in seconds (model-specific limits apply).",
        "image": "(Optional) Path to an existing input image for image-to-video generation. If using --image-prompt, this will typically be the same path as --openai-image-output.",
        "output": "(Optional) Output filename for the video.",
        "folder": "(Optional) Output folder path for the video (default: public/videos).",
        "image-prompt": "(Optional) Text prompt for OpenAI (GPT-image-1) to generate an initial image. This image will then be used for video generation.",
        "openai-image-output": "(Optional) Output path for the image generated by OpenAI (e.g., public/images/my-image.png). Required if --image-prompt is used and you want to specify the image name/path for the video step.",
        "aspect-ratio": "(Optional) Aspect ratio for the video (e.g., 16:9, 1:1). Support depends on the Replicate model."
      },
      "requires": [
        "REPLICATE_API_TOKEN in .env",
        "OPENAI_API_KEY in .env (if using --image-prompt)",
        "replicate package",
        "openai package",
        "ora package",
        "chalk package"
      ],
      "example": "npm run generate-video -- --image-prompt \\"A futuristic robot playing chess\\" --openai-image-output public/images/robot-chess.png --prompt \\"Animate the robot making a move, cinematic style\\" --image public/images/robot-chess.png --model kling-1.6 --duration 4 --output robot-chess-video.mp4"
    },
    "remove-background-advanced": {
      "description": "Advanced background removal tool using Sharp with color tolerance and edge detection",
      "tool": "run_terminal_cmd",
      "command": "npm run remove-background-advanced",
      "options": {
        "input": "Path to input image",
        "output": "Path to output image",
        "tolerance": "(Optional) Color tolerance for background detection (0-255, default: 30)"
      },
      "requires": ["sharp package"],
      "example": "npm run remove-background-advanced -- --input input.png --output output.png --tolerance 40"
    },
    "openai-image": {
      "description": "Generate and edit images using OpenAI's GPT-image-1 and DALL-E models",
      "tool": "run_terminal_cmd",
      "command": "npm run openai-image",
      "subcommands": {
        "generate": {
          "description": "Generate an image using OpenAI's image generation models",
          "options": {
            "prompt": "Required: Text prompt for image generation",
            "model": "(Optional) Model to use: \"gpt-image-1\" or \"dall-e-3\" (default: gpt-image-1)",
            "output": "(Optional) Output file path (default: openai-generated-image.png)",
            "folder": "(Optional) Output folder path (default: public/images)",
            "size": "(Optional) Image size: 1024x1024, 1792x1024, or 1024x1792 (default: 1024x1024)",
            "quality": "(Optional) Image quality: standard or hd - DALL-E only (default: standard)",
            "number": "(Optional) Number of images to generate (1-4) - DALL-E only (default: 1)",
            "reference-image": "(Optional) Reference image path for gpt-image-1 with reference",
            "creative": "(Optional) Creativity level for GPT-image-1: standard or vivid (default: standard)"
          },
          "example": "npm run openai-image -- generate -p \"A futuristic cityscape at sunset with flying cars\" -m gpt-image-1 -s 1792x1024 -c vivid"
        },
        "edit": {
          "description": "Edit an existing image using OpenAI's models",
          "options": {
            "input-image": "Required: Path to the input image to edit",
            "edit-prompt": "Required: Text prompt describing the edit to apply",
            "model": "(Optional) Model to use: \"gpt-image-1\" or \"dall-e-3\" (default: gpt-image-1)",
            "output": "(Optional) Output file path (default: openai-edited-image.png)",
            "folder": "(Optional) Output folder path (default: public/images)",
            "size": "(Optional) Image size: 1024x1024, 1792x1024, or 1024x1792 (default: 1024x1024)",
            "creative": "(Optional) Creativity level for GPT-image-1: standard or vivid (default: standard)"
          },
          "example": "npm run openai-image -- edit -i input.jpg -p \"Change the background to a tropical beach\" -m gpt-image-1"
        }
      },
      "requires": [
        "OPENAI_API_KEY in .env.local",
        "openai package",
        "axios package",
        "ora package",
        "chalk package"
      ]
    },
    "vercel-cli": {
      "description": "Directly interact with Vercel deployment platform for project management, environment variables, and domains",
      "tool": "run_terminal_cmd",
      "command": "npm run vercel",
      "options": {
        "deploy": {
          "description": "Deploy the application to Vercel",
          "options": {
            "environment": "(Optional) Deployment environment: production, preview, or development (default: preview)",
            "project": "(Optional) Project name (defaults to directory name)",
            "prod": "(Optional) Deploy to production (shorthand for --environment production)"
          }
        },
        "list": {
          "description": "List recent deployments",
          "options": {
            "count": "(Optional) Number of deployments to show (default: 5)"
          }
        },
        "logs": {
          "description": "Show logs for the current project",
          "options": {
            "follow": "(Optional) Follow logs in real time",
            "deployment": "(Optional) Deployment ID"
          }
        },
        "domains": {
          "description": "Manage domains for your Vercel projects",
          "options": {
            "add": "(Optional) Add a domain",
            "remove": "(Optional) Remove a domain",
            "list": "(Optional) List all domains"
          }
        },
        "env": {
          "description": "Manage environment variables",
          "options": {
            "add": "(Optional) Add an environment variable (format: key=value)",
            "remove": "(Optional) Remove an environment variable",
            "list": "(Optional) List all environment variables",
            "environment": "(Optional) Environment: development, preview, or production (default: development)"
          }
        },
        "promote": {
          "description": "Promote a deployment to production",
          "arguments": "<url-or-id>: Deployment URL or ID to promote"
        }
      },
      "requires": [
        "Vercel CLI (will be auto-installed if not present)",
        "Vercel account authentication"
      ],
      "example": "npm run vercel -- deploy --prod"
    },
    "github-cli": {
      "description": "Interact with GitHub repositories, pull requests, issues, and workflows directly from the command line",
      "tool": "run_terminal_cmd",
      "command": "npm run github",
      "options": {
        "auth": {
          "description": "Manage GitHub authentication",
          "options": {
            "login": "(Optional) Log in to GitHub (-l, --login)",
            "status": "(Optional) View authentication status (-s, --status)",
            "refresh": "(Optional) Refresh stored authentication credentials (-r, --refresh)",
            "logout": "(Optional) Log out of GitHub (-o, --logout)"
          }
        },
        "pr-create": {
          "description": "Create a pull request",
          "options": {
            "title": "(Optional) Pull request title",
            "body": "(Optional) Pull request body",
            "base": "(Optional) Base branch name",
            "draft": "(Optional) Create draft pull request",
            "fill": "(Optional) Use commit info for title/body"
          }
        },
        "pr-list": {
          "description": "List and filter pull requests",
          "options": {
            "state": "(Optional) Filter by state: open, closed, merged, all (default: open)",
            "limit": "(Optional) Maximum number of items to fetch (default: 30)",
            "assignee": "(Optional) Filter by assignee",
            "author": "(Optional) Filter by author",
            "base": "(Optional) Filter by base branch",
            "web": "(Optional) Open list in the browser"
          }
        },
        "pr-view": {
          "description": "View pull request details",
          "arguments": "[number]: PR number or URL, if omitted the PR from the current branch is displayed",
          "options": {
            "web": "(Optional) Open in web browser"
          }
        },
        "issue-create": {
          "description": "Create a new issue",
          "options": {
            "title": "(Optional) Issue title",
            "body": "(Optional) Issue body",
            "assignee": "(Optional) Assign people by their login",
            "label": "(Optional) Add labels by name",
            "project": "(Optional) Add issue to project",
            "milestone": "(Optional) Add issue to milestone",
            "web": "(Optional) Open new issue in the web browser"
          }
        },
        "issue-list": {
          "description": "List and filter issues",
          "options": {
            "state": "(Optional) Filter by state: open, closed, all (default: open)",
            "limit": "(Optional) Maximum number of issues to fetch (default: 30)",
            "assignee": "(Optional) Filter by assignee",
            "author": "(Optional) Filter by author",
            "label": "(Optional) Filter by label",
            "milestone": "(Optional) Filter by milestone",
            "web": "(Optional) Open list in the browser"
          }
        },
        "release-create": {
          "description": "Create a new release",
          "arguments": "<tag>: Tag name for the release",
          "options": {
            "title": "(Optional) Release title",
            "notes": "(Optional) Release notes",
            "notes-file": "(Optional) Read release notes from file",
            "draft": "(Optional) Save release as draft instead of publishing",
            "prerelease": "(Optional) Mark release as prerelease",
            "generate-notes": "(Optional) Automatically generate release notes"
          }
        },
        "release-list": {
          "description": "List releases in a repository",
          "options": {
            "limit": "(Optional) Maximum number of releases to fetch (default: 30)"
          }
        },
        "repo": {
          "description": "Manage repositories",
          "options": {
            "create": "(Optional) Create a new repository",
            "description": "(Optional) Repository description",
            "homepage": "(Optional) Repository homepage URL",
            "private": "(Optional) Make the repository private",
            "team": "(Optional) The name of the organization team to grant access to",
            "view": "(Optional) View repository details",
            "web": "(Optional) Open in web browser",
            "list": "(Optional) List your repositories"
          }
        },
        "workflow": {
          "description": "Manage GitHub Actions workflows",
          "options": {
            "list": "(Optional) List workflows",
            "run": "(Optional) Run a workflow by name or ID",
            "view": "(Optional) View a specific workflow",
            "enable": "(Optional) Enable a workflow by name or ID",
            "disable": "(Optional) Disable a workflow by name or ID"
          }
        },
        "tasks": {
          "description": "List and manage tasks from GitHub Projects and Issues",
          "options": {
            "project": "(Optional) Specify project ID or number to list tasks from",
            "repository": "(Optional) Specify repository in owner/repo format (default: current repository)",
            "status": "(Optional) Filter by status: open, closed, all (default: open)",
            "label": "(Optional) Filter by label",
            "assignee": "(Optional) Filter by assignee",
            "limit": "(Optional) Maximum number of tasks to fetch (default: 30)",
            "format": "(Optional) Output format: table, json, or simple (default: table)",
            "web": "(Optional) Open tasks in the web browser"
          }
        }
      },
      "requires": [
        "GitHub CLI (will be auto-installed if not present)",
        "GitHub account authentication"
      ],
      "example": "npm run github -- pr-create --title \"New feature\" --body \"This PR adds a new feature\""
    }
  }
}
</command_line_tools>

<documentation>
  ## Documentation and Context Files
  Reference these files for understanding the project. Use `read_file` for `@*.md` files. Use `fetch_rules` for `@*.mdc` files.
    - `@description.md`: App description, use cases, features.
    - `@architecture.md`: Tech stack, folder structure, testing frameworks.
    - `@datamodel.md`: Entities, attributes, relationships.
    - `@frontend.md`: Views/screens, UI/UX patterns, styling.
    - `@backend.md`: API endpoints, authentication, service architecture.
    - `@todo.md`: Task list (✅ done, ⏳ in progress, ❌ not started). Update status, don't remove tasks.
    - `@ai_changelog.md`: Log of changes made by AI. Add concise summaries here.
    - `@learnings.md`: Technical learnings, best practices, error solutions. Add new findings here.
    - `/.cursor/rules/@add-data-model.mdc`: How to add a new data model.
    - `/.cursor/rules/@admin-api-protection.mdc`: How to protect the admin API.
    - `/.cursor/rules/@implement-frontend-page.mdc`: How to implement a new frontend page.
    - `/.cursor/rules/@implement-nextjs-api.mdc`: How to implement a new NextJS API route.
    - `/.cursor/rules/@implement-unit-tests.mdc`: How to implement unit tests.
    - `/.cursor/rules/@nextjs-json-translation-usage.mdc`: How to use JSON translations in Next.js.
    - `/.cursor/rules/@supabase-auth-implementation.mdc`: How to implement Supabase authentication.
    - `/.cursor/rules/@translation-guidelines.mdc`: Guidelines for translations.
    - `/.cursor/rules/@translation-management-tools.mdc`: Tools for managing translations.
    - `@package.json`: List of used npm packages and versions.
    - `lib/@brand-info.ts`: Brand information for content generation.

  **Link Handling:**
    - For `@filename.ext` links: Use `read_file` to access their content.
    - For `http://` or `https://` links: Use `web_search` to get information from the URL if needed for the task (e.g., documentation, error context). Do not assume you can directly access or parse the content without `web_search`.
</documentation>

## Core Actions & Workflow
Define high-level tasks. Follow the `## Request Processing Steps` below to execute these.

<actions>
  <use_tools>
    - **Goal:** Execute project-specific tools listed under `<command_line_tools>`.
    - **Steps:**
      1. Identify the correct command and options based on the user request and tool definition.
      2. Use `run_terminal_cmd` to execute the command.
  </use_tools>

  <document>
     - **Goal:** Update documentation files.
     - **Steps:**
       1. Read relevant documentation files (`@*.md`).
       2. Use `edit_file` to make necessary updates based on the task. Focus on the specific files mentioned in the `<documentation>` section (e.g., `ai_changelog.md`, `todo.md`, `learnings.md`).
  </document>

  <research>
  - **Goal:** Understand a task or topic thoroughly before planning.
  - **Steps:**
    1. **Gather Context:**
        - Read relevant `@*.md` files from `<documentation>`.
        - Fetch relevant `@*.mdc` rules using `fetch_rules`.
        - Use `codebase_search` to find relevant existing code snippets.
        - Use `web_search` for external information, documentation, or examples (perform at least one search).
    2. **Analyze & Plan:**
        - Synthesize gathered information.
        - Outline the plan: What needs to be done? What tools are required?
        - Identify any missing information needed from the user.
    3. **Present Findings:** Clearly state the analysis, plan, and any questions for the user.
  </research>

  <fix>
  - **Goal:** Diagnose and resolve an error.
  - **Steps:**
    1. **Gather Context:**
        - Read `docs/learnings.md` for previous solutions (`read_file`).
        - If error messages contain URLs, use `web_search` to understand them.
        - Fetch relevant `@*.mdc` rules (`fetch_rules`).
        - Use `web_search` for general error resolution information.
    2. **Iterative Fixing Loop:**
        a. **Hypothesize:** Based on context, identify 1-2 likely causes.
        b. **Validate Hypothesis (Optional but Recommended):** Use `edit_file` to add temporary logging, then use `run_terminal_cmd` to run relevant tests/code and observe logs.
        c. **Implement Fix:** Use `edit_file` to apply the proposed code change.
        d. **Validate Fix:** Use `run_terminal_cmd` to run tests or execute the relevant code path.
        e. **Record Outcome:**
            - If fixed: Update `docs/learnings.md` with the solution (`edit_file`). Delete `/temp/fix_backlog.md` if it exists (`delete_file`).
            - If not fixed: Create or update `/temp/fix_backlog.md` with what was tried (`edit_file`). Return to step (a). *Do not loop more than 3 times on the same core issue without asking the user.*
  </fix>

  <validate>
  - **Goal:** Implement and run tests, fixing any failures.
  - **Steps:**
    1. **Understand Requirements:**
        - Read `docs/architecture.md` for testing practices (`read_file`).
        - Fetch `@implement-unit-tests.mdc` rule (`fetch_rules`).
    2. **Write Unit Tests:**
        - Use `edit_file` to create/update unit test files (e.g., `__tests__/*.test.ts`).
    3. **Run & Fix Unit Tests:**
        - Execute tests using `run_terminal_cmd` (e.g., `npm test`).
        - If errors occur, use the `<fix>` action flow to resolve them.
    4. **Write E2E Tests:**
        - Use `edit_file` to create/update E2E test files (e.g., in `cypress/`).
    5. **Run & Fix E2E Tests:**
        - Execute tests using `run_terminal_cmd` (e.g., `npm run cypress:run`).
        - If errors occur, use the `<fix>` action flow to resolve them.
    6. **Document:** Ensure any non-trivial fixes are documented in `docs/learnings.md` as part of the `<fix>` action.
    7. **Repeat:** Continue until all relevant tests pass.
  </validate>

  <record>
   - **Goal:** Document completed work and update the task backlog.
   - **Steps:**
     1. Use `edit_file` to add a summary to `docs/ai_changelog.md`.
     2. Use `edit_file` to update the status (✅, ⏳, ❌) of the relevant task(s) in `docs/todo.md`. **Do not remove tasks.**
  </record>

  <design>
   - **Goal:** Design a frontend feature.
   - **Steps:**
     1. Read `docs/frontend.md` for UI/UX guidelines (`read_file`).
     2. Describe the design (components, layout, flow) and use `edit_file` to update `docs/frontend.md`.
     3. Generate required images/illustrations using `run_terminal_cmd` with appropriate image generation tools (e.g., `gemini-image`, prefer `imagen` or `gemini` models). Specify output folder like `public/images`.
     4. Optimize generated images using `run_terminal_cmd` with `image-optimizer`.
     5. Briefly summarize the design and generated assets for the user.
  </design>

  <develop>
   - **Goal:** Implement the code for a feature (frontend/backend).
   - **Steps:**
     1. Fetch relevant rules (`@implement-*.mdc`) using `fetch_rules`.
     2. Use `edit_file` to implement the required code changes across necessary files (components, API routes, types, etc.). Ensure imports and dependencies are handled.
  </develop>

  <invent>
    - **Goal:** Create a new command-line tool.
    - **Steps:**
      1. Implement the tool script (e.g., in `tools/` directory) using `edit_file`.
      2. Add/update the tool's definition in the `<command_line_tools>` section of *this* `.cursorrules` file using `edit_file`. Ensure `tool` is set to `run_terminal_cmd`.
      3. Test the new tool using `run_terminal_cmd`.
      4. Use the `<fix>` action flow to debug any issues until the tool executes successfully.
  </invent>

  <commit>
    - **Goal:** Commit current changes to git.
    - **Steps:**
      1. Use `run_terminal_cmd` to run `git add .`.
      2. Use `run_terminal_cmd` to run `git commit -m "feat: [Descriptive summary of changes]"`. Adapt the message prefix (e.g., `fix:`, `docs:`, `chore:`) as appropriate.
  </commit>

  <implement_ai>
    - **Goal:** Implement AI/LLM features, like Gemini prompts or functions.
    - **Steps:**
      1. **Review Examples:** Read `tools/gemini.ts` using `read_file` to understand existing patterns.
      2. **Implement:** Use `edit_file` to add the AI logic.
      3. **Library Usage:** **Crucially**, always import and use the `@google/genai` library, *not* the older `generativeai` package.
      4. **Integration:** Integrate the AI logic into relevant frontend or backend components as needed, potentially using the `<develop>` action.
      5. **Testing:** Ensure the feature is tested, potentially using the `<validate>` action.
  </implement_ai>

  <localize>
    - **Goal:** Create or update translations for the application with natural, culturally appropriate phrasing.
    - **Steps:**
      1. **Understand Context:**
         - Read `messages/README.md` to understand the localization structure.
         - Examine existing translations in the target namespace(s) across all locales to understand tone and style.
         - Read related components to understand how the translations are used in context.
      
      2. **Translation Approach:**
         - **DO NOT** translate word-for-word. Prioritize natural, idiomatic expressions in each target language.
         - Consider cultural context for each language (Finnish, Swedish, English).
         - Maintain consistent terminology within each feature/namespace.
         - Preserve placeholders (e.g., `{count}`, `{name}`) and formatting tags.
         - Ensure translations fit UI space constraints while conveying the full meaning.
      
      3. **Language-Specific Guidance:**
         - **Finnish (fi):**
           - Use shorter constructions where possible (Finnish words tend to be longer).
           - Consider compound word formation rules (yhdyssanat).
           - Use appropriate formal/informal tone (generally more formal for business applications).
           - Handle cases properly (Finnish has 15 grammatical cases).
         
         - **Swedish (sv):**
           - Pay attention to definite/indefinite forms.
           - Use appropriate formal/informal tone ("ni" vs "du").
           - Consider gender agreement in adjectives.
           - Maintain natural word order in questions and statements.
         
         - **English (en):**
           - Use clear, concise phrasing.
           - Follow American English conventions unless otherwise specified.
           - Avoid idioms that may not translate well.

      4. **Implementation:**
         - Identify the correct namespace file for each locale (`en/`, `fi/`, `sv/`).
         - Use `edit_file` to add new translations or update existing ones.
         - Maintain JSON structure and formatting consistency.
         - Keep translations organized by logical sections within the namespace.
      
      5. **Validation:**
         - Run `npm run check-translations` to verify translation completeness.
         - If possible, have native speakers review translations (or note this as a post-implementation recommendation).
         - Test in the UI to ensure proper rendering and context appropriateness.
      
      6. **Documentation:**
         - Update the localization report if needed.
         - Note any challenging translations or decisions in comments.
  </localize>
</actions>

<behavioral_rules>
- **Existing Project:** NEVER create a new project. Analyze existing structure.
- **Up-to-date Info:** Do NOT rely solely on internal knowledge. ALWAYS use `web_search` or `gemini --ground` to verify external API/library documentation, versions, and best practices.
- **Latest Libraries:** Prefer latest stable versions for dependencies.
- **Cautious Edits:** Use `codebase_search`/`grep_search` to understand impact before modifying existing code. Avoid deletions unless clearly required.
- **Follow Instructions:** Adhere precisely to `<action>` steps and these rules.
- **Persistence:** Be persistent, do not give up. Don't stop when you have not completed the task. 
- **Simplicity:** Prefer the simplest, most direct solution meeting all requirements.
- **Tool Usage:** Use provided tools appropriately. Explain *why* a tool is used and *how* the prompt is constructed (especially for Gemini).
- **Clarity:** Communicate plans, actions, results clearly. Ask clarifying questions if ambiguous.

### Model-Specific Behavior:
- **For Claude (Anthropic):**
    - **Exact Request Fulfillment:** Implement *only* what is explicitly asked. No extras.
    - Confirm all parts of the request are addressed, nothing more.
    - Ask: "Am I adding anything not explicitly requested?" If yes, remove it.
    - Avoid suggesting alternatives unless asked.

- **For Gemini (Google):**
    - **Follow Instructions Precisely:** Execute user instructions exactly as written.
    - **Adhere Strictly:** Follow the specified workflow and action steps rigorously.
    - **Maintain Structure:** Use consistent formatting as specified.
    - **Leverage Context:** Actively incorporate context from documentation (`@*.md`), rules (`@*.mdc`), codebase searches (`codebase_search`), and files/URLs into prompts.
    - **Iterate When Necessary:** Refine outputs through follow-up prompts if needed.

- **For GPT (OpenAI) and Grok (X.AI):**
    - Be complete, aim for full task completion per run.
    - Only ask user for major decisions.
</behavioral_rules>

## Request Processing Steps
Follow these steps sequentially for **every** user request and follow behavioral rules above:

1.  **Tool Use Check:** If the user *explicitly* requests a specific tool, execute it using the `<use_tools>` action and respond. **Stop processing here.**
2.  **Initial Analysis:**
    * Read the user request carefully.
    * Consult `<documentation>` (`read_file`) and potentially fetch rules (`Workspace_rules`) for context.
    * Identify the primary goal.
    * Determine the most relevant `<action>`. Default to `<research>` if unclear.
    * List affected architecture areas.
    * **Present Analysis:**
        ```
        Request type: [Inferred type]
        Primary Action: [<Chosen action>]
        Affected Areas: [List areas]
        Plan Overview: [Briefly mention key steps/tools, e.g., "Read docs, formulate prompt for edit_file, run tests"]
        ```
3.  **Task Planning (if complex):**
    * For multi-step actions (`<develop>`, `<validate>`, `<design>`), break down into sub-tasks.
    * Use `edit_file` to add sub-tasks to `@todo.md` (marked ❌). Include development, testing, documentation steps.
    * Inform the user the plan is in `@todo.md`.
4.  **Action Execution:**
    * State: `Starting Action: <action name>...`
    * Execute steps within the chosen `<action>`, focusing on providing **clear, context-rich prompts** to tools like `edit_file` and `run_terminal_cmd` (especially for `gemini` tools).
    * Adhere strictly to `<behavior_rules>`.
    * Review outputs and iterate with follow-up prompts if necessary.
    * State: `Completed Action: <action name>.`
5.  **Final Recording (on task completion):**
    * Once the *entire* request is fulfilled:
        * Summarize significant changes.
        * Execute `<record>` action (update `@ai_changelog.md`, `@todo.md`).
        * Ensure `@learnings.md` was updated during `<fix>` or `<invent>` actions if applicable.